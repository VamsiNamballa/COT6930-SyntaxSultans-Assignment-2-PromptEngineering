{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-Shot Prompting\n",
    "\n",
    "Zero-shot prompting refers to a technique in prompt engineering where you provide a model with a task without any prior examples. The model is expected to understand and generate a response or complete the task purely based on the given instruction.\n",
    "\n",
    "In other words, the model is given \"zero\" prior training examples or demonstrations in the prompt and relies on its pre-trained knowledge to infer what is needed.\n",
    "\n",
    "## References:\n",
    "* [Wei et al. (2022)](https://arxiv.org/pdf/2109.01652.pdf): demonstrate how instruction tuning improves zero-shot learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fzero_shot.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'Generate a requirement analysis for an educational chatbot that simplifies advanced topics for students using toy examples.', 'stream': False, 'options': {'temperature': 0.7, 'num_ctx': 200, 'num_predict': 300}}\n",
      "**Requirement Analysis: Educational Chatbot for Simplifying Advanced Topics**\n",
      "\n",
      "**Overview**\n",
      "\n",
      "The primary objective of this project is to develop an educational chatbot that simplifies complex concepts in various subjects, such as physics, mathematics, and computer science, using engaging toy examples.\n",
      "\n",
      "**Functional Requirements**\n",
      "\n",
      "1. **User Interface**\n",
      "\t* The chatbot should have a user-friendly interface that allows students to interact with it through natural language processing (NLP) or text input.\n",
      "\t* The interface should be accessible on multiple devices, including desktops, laptops, tablets, and smartphones.\n",
      "2. **Content Creation**\n",
      "\t* The chatbot should be able to generate content, including explanations, examples, and exercises, based on the user's input or predefined topics.\n",
      "\t* The content should be relevant, accurate, and engaging for students of various ages and skill levels.\n",
      "3. **Question Answering**\n",
      "\t* The chatbot should be able to answer questions posed by students using its generated content.\n",
      "\t* The answers should be concise, clear, and relevant to the topic at hand.\n",
      "4. **Learning Paths**\n",
      "\t* The chatbot should be able to create personalized learning paths based on a student's strengths, weaknesses, and interests.\n",
      "\t* The learning paths should be tailored to meet specific learning objectives or outcomes.\n",
      "5. **Feedback Mechanism**\n",
      "\t* The chatbot should have a feedback mechanism that allows students to provide input on its performance.\n",
      "\t* The feedback should be used to improve the\n",
      "Time taken: 7.856s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## ZERO-SHOT PROMPTING FOR REQUIREMENT ANALYSIS\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"Generate a requirement analysis for an educational chatbot that simplifies advanced topics for students using toy examples.\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "PROMPT = MESSAGE \n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"openweb-ui\",\n",
    "                         model=\"phi4:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7, \n",
    "                         num_ctx=200, \n",
    "                         num_predict=300)\n",
    "\n",
    "### YOU DON’T NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "response_time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if response_time: print(f'Time taken: {response_time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## How to improve it?\n",
    "\n",
    "* **Use Clear and Concise Instructions**: Be specific about the task and desired format.\n",
    "    * Bad Prompt: “Summarize this.”\n",
    "    * Good Prompt: “Summarize this paragraph in one sentence.”\n",
    "* **Add Context**: Providing background can help the model interpret ambiguous prompts better.\n",
    "* **Specify Output Format**: If a particular structure is needed, describe it in the instruction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
