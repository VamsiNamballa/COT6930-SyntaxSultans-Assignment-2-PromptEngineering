{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template Prompting\n",
    "\n",
    "Prompt Template Prompting refers to a technique where predefined templates are used to construct effective prompts that guide large language models (LLMs) to generate responses tailored to specific use cases. The templates typically contain static text combined with dynamic input variables, allowing for consistent, reusable, and customizable prompts.\n",
    "\n",
    "Prompt templates are widely used across various domains, such as:\n",
    "* **Question Generation**: Templates can generate quiz questions by filling in variables related to topics.\n",
    "* **Text Summarization**: Static instructions combined with variable documents or inputs allow flexible summarization.\n",
    "* **Coding Assistance**: Dynamic prompts help LLMs generate code snippets for different programming tasks.\n",
    "\n",
    "## References:\n",
    "\n",
    "* (OpenAI Documentation for Prompt Engineering)[https://platform.openai.com/docs/guides/prompt-engineering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running this code on MyBind.org\n",
    "\n",
    "Note: remember that you will need to **adjust CONFIG** with **proper URL and API_KEY**!\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GenILab-FAU/prompt-eng/HEAD?urlpath=%2Fdoc%2Ftree%2Fprompt-eng%2Fprompt_template.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.2:latest', 'prompt': 'Act like you are a math teacher. Answer to this question from an student:\\n984 * log(2)\\nProvide the answer only. No explanations!', 'stream': False, 'options': {'temperature': 1.0, 'num_ctx': 100, 'num_predict': 100}}\n",
      "!!ERROR!! HTTP Response=400, {\"detail\":\"Model not found\"}\n",
      "Time taken: -1s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## PROMPT TEMPLATE PROMPTING\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Adjust the inbounding  Prompt, simulating inbounding requests from users or other systems\n",
    "MESSAGE = \"984 * log(2)\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "TEMPLATE_BEFORE=\"Act like you are a math teacher. Answer to this question from an student:\"\n",
    "TEMPLATE_AFTER=\"Provide the answer only. No explanations!\"\n",
    "PROMPT = TEMPLATE_BEFORE + '\\n' + MESSAGE + '\\n' + TEMPLATE_AFTER\n",
    "\n",
    "#### (3) Configure the Model request, simulating Workflow Orchestration\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=1.0, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=100)\n",
    "\n",
    "### YOU DONT NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Level-1 Prompting using prompt-template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'phi4:latest', 'messages': [{'role': 'user', 'content': 'You are an AI expert in chatbot development and educational technology.\\nAnalyze and list the functional requirements needed to enhance an existing Discord-based chatbot by adding educational functionality that helps students understand advanced concepts easily.\\n\\nProvide a general overview without strict formatting.'}]}\n",
      "Enhancing a Discord-based chatbot with educational functionalities requires careful consideration of various aspects to ensure it effectively aids students in understanding advanced concepts. Here’s a breakdown of the functional requirements needed:\n",
      "\n",
      "1. **Integration and Compatibility**:\n",
      "   - Seamless integration into existing Discord servers while maintaining compatibility across different versions.\n",
      "   - Ability to handle multiple languages if targeting diverse student demographics.\n",
      "\n",
      "2. **User Authentication and Privacy**:\n",
      "   - Secure login mechanisms, possibly integrating with school or educational institution credentials.\n",
      "   - Ensure compliance with data protection regulations like GDPR, especially for minors.\n",
      "\n",
      "3. **Content Management System (CMS)**:\n",
      "   - A robust CMS that allows educators to easily update and manage educational content.\n",
      "   - Version control for tracking changes in educational materials and updates.\n",
      "\n",
      "4. **Knowledge Base and Resource Access**:\n",
      "   - A comprehensive knowledge base with access to textbooks, research papers, and online resources like Khan Academy or Coursera.\n",
      "   - Capability to link external multimedia resources (videos, interactive simulations) relevant to advanced concepts.\n",
      "\n",
      "5. **Interactive Learning Modules**:\n",
      "   - Development of interactive modules for complex topics such as calculus, programming, physics, etc., incorporating quizzes and problem-solving exercises.\n",
      "   - Adaptive learning paths that adjust difficulty based on the user's performance and progress.\n",
      "\n",
      "6. **Natural Language Processing (NLP) and AI Capabilities**:\n",
      "   - Advanced NLP to understand and process student queries effectively in natural language.\n",
      "   - Machine Learning algorithms to provide personalized learning recommendations and feedback.\n",
      "\n",
      "7. **Real-time Assistance**:\n",
      "   - Instant messaging support for immediate help with questions, leveraging AI for quick responses or routing to human educators if necessary.\n",
      "   - Integration of a virtual tutor feature that can simulate one-on-one tutoring sessions.\n",
      "\n",
      "8. **Collaboration Tools**:\n",
      "   - Features to facilitate group study sessions and collaborative projects, such as shared whiteboards and document editing.\n",
      "   - Options for scheduling study groups or live Q&A sessions with educators.\n",
      "\n",
      "9. **Progress Tracking and Reporting**:\n",
      "   - Detailed tracking of user progress through learning modules, quizzes, and activities.\n",
      "   - Generation of personalized reports for students and feedback mechanisms for continuous improvement.\n",
      "\n",
      "10. **Gamification Elements**:\n",
      "    - Incorporation of gamified elements like badges, leaderboards, and rewards to increase student engagement and motivation.\n",
      "    - Challenges or competitions that encourage peer-to-peer learning and teamwork.\n",
      "\n",
      "11. **Feedback Mechanism**:\n",
      "    - Channels for students and educators to provide feedback on the chatbot's performance and content quality.\n",
      "    - Regular updates based on user feedback to improve functionality and user experience.\n",
      "\n",
      "12. **Scalability and Performance**:\n",
      "    - Ensure the system can scale efficiently as more users join, without compromising response times or accuracy.\n",
      "    - Load testing to ensure smooth operation during peak usage periods like exam preparations or assignment deadlines.\n",
      "\n",
      "By addressing these functional requirements, the enhanced chatbot will be well-equipped to provide substantial educational support within Discord communities, helping students grasp advanced concepts with greater ease and engagement.\n",
      "Time taken: 13.526s\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## LEVEL-1 PROMPT TEMPLATE FOR EDUCATIONAL CHATBOT\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Define the Prompt Template\n",
    "TEMPLATE_BEFORE = \"You are an AI expert in chatbot development and educational technology.\\n\"\n",
    "\n",
    "MESSAGE = (\"Analyze and list the functional requirements needed to enhance an existing Discord-based chatbot \"\n",
    "           \"by adding educational functionality that helps students understand advanced concepts easily.\\n\")\n",
    "\n",
    "TEMPLATE_AFTER = \"Provide a general overview without strict formatting.\"\n",
    "\n",
    "#### (2) Adjust the Prompt Engineering Technique to be applied, simulating Workflow Templates\n",
    "\n",
    "## @TODO \n",
    "PROMPT = TEMPLATE_BEFORE + MESSAGE + \"\\n\" + TEMPLATE_AFTER\n",
    "\n",
    "\n",
    "#### (3) Configure the Model Request\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"open-webui\",\n",
    "                         model=\"phi4:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=300)\n",
    "\n",
    "### YOU DON’T NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f\"Time taken: {time}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt asking for a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'phi4:latest', 'messages': [{'role': 'user', 'content': 'You are an AI expert in prompt engineering and chatbot development.\\nGenerate a well-structured prompt that can be used to perform a requirement analysis for enhancing an existing Discord-based chatbot by adding educational functionality. The chatbot should help students understand advanced concepts easily using toy examples.\\n\\nEnsure that the generated prompt is clear, detailed, and effective for eliciting a comprehensive requirement analysis.'}]}\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## LEVEL-1 PROMPT TEMPLATE FOR GENERATING A REQUIREMENT ANALYSIS PROMPT\n",
    "##\n",
    "\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "#### (1) Define the Prompt Template\n",
    "TEMPLATE_BEFORE = \"You are an AI expert in prompt engineering and chatbot development.\\n\"\n",
    "\n",
    "MESSAGE = (\"Generate a well-structured prompt that can be used to perform a requirement analysis \"\n",
    "           \"for enhancing an existing Discord-based chatbot by adding educational functionality. \"\n",
    "           \"The chatbot should help students understand advanced concepts easily using toy examples.\\n\")\n",
    "\n",
    "TEMPLATE_AFTER = \"Ensure that the generated prompt is clear, detailed, and effective for eliciting a comprehensive requirement analysis.\"\n",
    "\n",
    "#### (2) Assembling the Final Prompt\n",
    "PROMPT = TEMPLATE_BEFORE + MESSAGE + \"\\n\" + TEMPLATE_AFTER\n",
    "\n",
    "#### (3) Configure the Model Request\n",
    "# Documentation: https://github.com/ollama/ollama/blob/main/docs/api.md\n",
    "payload = create_payload(target=\"open-webui\",\n",
    "                         model=\"phi4:latest\", \n",
    "                         prompt=PROMPT, \n",
    "                         temperature=0.7, \n",
    "                         num_ctx=100, \n",
    "                         num_predict=1000)\n",
    "\n",
    "### YOU DON’T NEED TO CONFIGURE ANYTHING ELSE FROM THIS POINT\n",
    "# Send out to the model\n",
    "time, response = model_req(payload=payload)\n",
    "print(response)\n",
    "if time: print(f\"Time taken: {time}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
